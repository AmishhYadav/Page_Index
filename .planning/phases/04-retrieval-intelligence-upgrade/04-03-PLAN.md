# Plan 04-03: Cross-Encoder Re-Ranking Layer

## Goal
Add a cross-encoder model that re-scores (query, section) pairs after retrieval to dramatically improve precision before LLM generation.

<tasks>
  <task id="1" title="Add Dependencies">
    <description>Add `sentence-transformers` to `requirements.txt`. Add `RERANKER_MODEL` and `RERANKER_ENABLED` to `app/core/config.py`.</description>
  </task>
  <task id="2" title="Implement ReRanker Service">
    <description>Create `app/services/reranker.py`. Implement `ReRanker.rerank(query, results, top_n)`:
    1. Load the cross-encoder model (lazy singleton).
    2. Score each `(query, section_content)` pair.
    3. Sort by cross-encoder score descending.
    4. Return top_n results with updated scores.</description>
  </task>
  <task id="3" title="Integrate into Pipeline">
    <description>Update `app/api/v1/ask.py` to call `ReRanker.rerank()` between retrieval and LLM generation. Log re-ranking latency separately.</description>
  </task>
  <task id="4" title="Verification">
    <description>Write a test with known-relevant and known-irrelevant sections. Assert that the cross-encoder promotes the relevant section above the irrelevant one.</description>
  </task>
</tasks>

<verification>
1. Cross-encoder model loads successfully and produces float scores.
2. Re-ranked results differ from raw retrieval order (relevant promoted).
3. `RERANKER_ENABLED=false` bypasses re-ranking (backward compatible).
</verification>

<must_haves>
- Lazy model loading (don't block startup).
- Configurable model name for swapping architectures.
- Graceful fallback if model fails to load.
</must_haves>
